{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "genius_TOKEN = 'sD0C3epnJdfOQQK4eIC45dHl-Qv7DipToGpuj1n4WeuG5_LDP1HKn31w5Cn1lOux'\n",
    "genius = lyricsgenius.Genius(genius_TOKEN)\n",
    "genius.verbose = False\n",
    "genius.remove_section_headers = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify(df):\n",
    "    genres = []\n",
    "    languages = []\n",
    "    countries = []\n",
    "    for x,y,z in zip(df['Genres'],df['Languages'],df['Countries']):\n",
    "        g = re.findall(': \\\"(.*?)\\\"', x)\n",
    "        l = re.findall(': \\\"(.*?)\\\"', y)\n",
    "        c = re.findall(': \\\"(.*?)\\\"', z)\n",
    "        genres.append(g)\n",
    "        languages.append(l)\n",
    "        countries.append(c)\n",
    "    df['Genres'] = genres\n",
    "    df['Languages'] = languages\n",
    "    df['Countries'] = countries\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies = listify(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''years = []\n",
    "for x in movies['ReleaseDate']:\n",
    "    x = str(x)[:4]\n",
    "    if x != 'nan':\n",
    "        years.append(int(x))\n",
    "    else:\n",
    "        years.append(3000)\n",
    "movies['ReleaseDate'] = years'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies = movies[movies['ReleaseDate']>=1960]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=50000, max_df=0.8, min_df=20, norm='l2')\n",
    "tokenizer = vectorizer.build_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['toks'] = [tokenizer(summary) for summary in movies['Summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english = ['English Language' in m for m in movies['Languages']]\n",
    "movies = movies[is_english]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.reset_index()\n",
    "movies = movies.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiID</th>\n",
       "      <th>Title</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Summary</th>\n",
       "      <th>compound</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Thriller, Science Fiction, Horror, Adventure,...</td>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>-0.9913</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.786</td>\n",
       "      <td>[Set, in, the, second, half, of, the, 22nd, ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9363483</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>110.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[Thriller, Erotic thriller, Psychological thri...</td>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "      <td>-0.9985</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.724</td>\n",
       "      <td>[series, of, murders, of, rich, young, women, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18998739</td>\n",
       "      <td>The Sorcerer's Apprentice</td>\n",
       "      <td>2002</td>\n",
       "      <td>86.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[South Africa]</td>\n",
       "      <td>[Family Film, Fantasy, Adventure, World cinema]</td>\n",
       "      <td>Every hundred years, the evil Morgana  returns...</td>\n",
       "      <td>-0.8885</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.776</td>\n",
       "      <td>[Every, hundred, years, the, evil, Morgana, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6631279</td>\n",
       "      <td>Little city</td>\n",
       "      <td>1997</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Romantic comedy, Ensemble Film, Comedy-drama,...</td>\n",
       "      <td>Adam, a San Francisco-based artist who works a...</td>\n",
       "      <td>-0.7097</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.804</td>\n",
       "      <td>[Adam, San, Francisco, based, artist, who, wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171005</td>\n",
       "      <td>Henry V</td>\n",
       "      <td>1989</td>\n",
       "      <td>137.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[Costume drama, War film, Epic, Period piece, ...</td>\n",
       "      <td>{{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.903</td>\n",
       "      <td>[Plot, dateAct, 1Act, 2Act, 3Act, 4Act, Finall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WikiID                      Title  ReleaseDate  Runtime  \\\n",
       "0    975900             Ghosts of Mars         2001     98.0   \n",
       "1   9363483           White Of The Eye         1987    110.0   \n",
       "2  18998739  The Sorcerer's Apprentice         2002     86.0   \n",
       "3   6631279                Little city         1997     93.0   \n",
       "4    171005                    Henry V         1989    137.0   \n",
       "\n",
       "            Languages                   Countries  \\\n",
       "0  [English Language]  [United States of America]   \n",
       "1  [English Language]            [United Kingdom]   \n",
       "2  [English Language]              [South Africa]   \n",
       "3  [English Language]  [United States of America]   \n",
       "4  [English Language]            [United Kingdom]   \n",
       "\n",
       "                                              Genres  \\\n",
       "0  [Thriller, Science Fiction, Horror, Adventure,...   \n",
       "1  [Thriller, Erotic thriller, Psychological thri...   \n",
       "2    [Family Film, Fantasy, Adventure, World cinema]   \n",
       "3  [Romantic comedy, Ensemble Film, Comedy-drama,...   \n",
       "4  [Costume drama, War film, Epic, Period piece, ...   \n",
       "\n",
       "                                             Summary  compound    pos    neg  \\\n",
       "0  Set in the second half of the 22nd century, th...   -0.9913  0.065  0.150   \n",
       "1  A series of murders of rich young women throug...   -0.9985  0.078  0.198   \n",
       "2  Every hundred years, the evil Morgana  returns...   -0.8885  0.092  0.131   \n",
       "3  Adam, a San Francisco-based artist who works a...   -0.7097  0.089  0.108   \n",
       "4  {{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...    0.3182  0.065  0.032   \n",
       "\n",
       "     neu                                               toks  \n",
       "0  0.786  [Set, in, the, second, half, of, the, 22nd, ce...  \n",
       "1  0.724  [series, of, murders, of, rich, young, women, ...  \n",
       "2  0.776  [Every, hundred, years, the, evil, Morgana, re...  \n",
       "3  0.804  [Adam, San, Francisco, based, artist, who, wor...  \n",
       "4  0.903  [Plot, dateAct, 1Act, 2Act, 3Act, 4Act, Finall...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = genius.search_song('XO','eden')\n",
    "x = analyzer.polarity_scores(s.lyrics)\n",
    "x1 = x['pos']\n",
    "y1 = x['neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = []\n",
    "for x2,y2 in tuple(zip(movies['pos'], movies['neg'])):\n",
    "    dist.append(math.sqrt((x1 - x2)**2 + (y1 - y2)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24775"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_movies = len(movies)\n",
    "num_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inverted_index(movies):\n",
    "    word_set = []\n",
    "    for t in movies['toks']:\n",
    "        word_set+=t\n",
    "    word_set = set(word_set)\n",
    "    word_dict = {w: [] for w in word_set}\n",
    "    for i in range(len(movies)):\n",
    "        for w in set(movies['toks'][i]):\n",
    "            if w in movies['toks'][i]:\n",
    "                word_dict[w].append((i,movies['toks'][i].count(w)))\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#took long time to run, only needs to be done once\n",
    "idx = build_inverted_index(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('inv_idx.npy', idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 21.1 GiB for an array with shape (117649, 24054) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-fb443033bb3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   1245\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"only recognize index or columns for orient\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    472\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\env\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# columns if columns is not None else []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[1;32m~\\env\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;31m# list of lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m     \u001b[1;31m# gh-26429 do not raise user-facing AssertionError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.to_object_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 21.1 GiB for an array with shape (117649, 24054) and data type object"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(idx,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inv_idx = np.load('inv_idx.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('inv_idx.txt', 'w') as file:\n",
    "#    json.dump(idx, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('app/inv_idx.txt', 'r') as file:\n",
    "    inv_idx = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inv_idx.csv', 'w', encoding='utf-8') as f: \n",
    "    l = []\n",
    "    for k, v in idx.items():\n",
    "        l.append('%s: %s' % (str(k), str(v)))\n",
    "    f.write(', '.join(l)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-52fe68798ba2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0minv_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "with open('inv_idx.csv', 'r', encoding='utf-8') as f:\n",
    "    inv_idx = {}\n",
    "    l = f.read().split(',')\n",
    "    for i in l:\n",
    "        values = i.split(': ')\n",
    "        inv_idx[values[0]] = values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('inv_idx.pkl', 'wb') as f:\n",
    "#    pickle.dump(inv_idx, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('inv_idx.txt', 'r') as file:\n",
    "#    new_d = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(inv_idx, n_docs, min_df=20, max_df_ratio=0.8):\n",
    "    idf = {x: math.log2(n_docs/(1+len(inv_idx[x]))) for x in inv_idx \n",
    "           if len(inv_idx[x])>=min_df and len(inv_idx[x])/n_docs<=max_df_ratio}\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = compute_idf(inv_idx,num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_doc_norms(index, idf, n_docs):\n",
    "    norms_sq = np.zeros(n_docs)\n",
    "    for t in idf:\n",
    "        for (doc,cnt) in index[t]:\n",
    "            norms_sq[doc] += (cnt*idf[t])**2\n",
    "    return np.sqrt(norms_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#norms = compute_doc_norms(inv_idx, idf, num_movies)\n",
    "#np.savetxt('norms.csv', norms, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.loadtxt('norms.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanjson(result):\n",
    "    title = result[result.find(\"Title\")+8:result.find(\"Year\")-3]\n",
    "    plot = result[result.find(\"Plot\")+7:result.find(\"Language\")-3]\n",
    "    try:\n",
    "        review_imdb = float(result[result.find(\n",
    "        '\"Internet Movie Database\",\"Value\":\"')+35:result.find('Source\":\"Rotten Tomatoes\"')-8])\n",
    "    except:\n",
    "        review_imdb = -1\n",
    "    try:\n",
    "        review_rotten = float(result[result.find(\n",
    "        'Source\":\"Rotten Tomatoes\",\"Value\":')+35: result.find('},{\"Source\":\"Metacritic\"')-2])\n",
    "    except:\n",
    "        review_rotten = -1\n",
    "    return [title, plot, review_imdb, review_rotten]\n",
    "\n",
    "def response(result):\n",
    "    text = result[result.find('\"Response\":' )+12:]\n",
    "    return text.find('True') >-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "omdb_TOKEN = 'ce887dbd'\n",
    "def find_movie(movie):\n",
    "    title = \"\"\n",
    "    plot = \"\"\n",
    "    query = \"http://www.omdbapi.com/?apikey=\" + omdb_TOKEN + \"&t=\" + movie\n",
    "    params = {\"r\": \"json\", \"plot\": \"full\"}\n",
    "    result = requests.get(query, params)\n",
    "    if response(result.text):\n",
    "        json = cleanjson(result.text)\n",
    "        plot = json[1]\n",
    "        title = json[0]\n",
    "        review_imdb = json[2]\n",
    "        review_rotten = json[3]\n",
    "    else:\n",
    "        return \"ERROR\"\n",
    "    return (title, plot, review_imdb, review_rotten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_search(user_mov):\n",
    "    movie = find_movie(user_mov)\n",
    "    query = movie[1]\n",
    "    #query = ''\n",
    "    #if movie[0] in movie_titles:\n",
    "    #    query = movies['Summary'][title_to_index[movie[0]]]\n",
    "    #else:\n",
    "    #    query = movie[1]\n",
    "    scores = np.zeros(len(norms))\n",
    "    docs = [i for i in range(len(norms))]\n",
    "    q = query.lower()\n",
    "    q_tokens = tokenizer(q)\n",
    "    q_norm_sq = 0\n",
    "    for t in set(q_tokens):\n",
    "        if t in idf:\n",
    "            q_norm_sq += (q_tokens.count(t)*idf[t])**2\n",
    "            for (doc,cnt) in inv_idx[t]:\n",
    "                scores[doc] += (q_tokens.count(t)*cnt*idf[t]**2)/norms[doc]\n",
    "    q_norm = math.sqrt(q_norm_sq)\n",
    "    new_scores = [score/q_norm for score in scores]\n",
    "    result = sorted(tuple(zip(new_scores, docs)),reverse=True)\n",
    "    return result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = index_search('Memento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.16056939582947827, 35155),\n",
       " (0.15718873462135707, 13330),\n",
       " (0.15580892217745576, 37607),\n",
       " (0.1485379138540403, 2487),\n",
       " (0.14042652859711635, 34573),\n",
       " (0.13924014073325508, 17758),\n",
       " (0.13512155658997846, 15566),\n",
       " (0.1330696150046359, 3533),\n",
       " (0.13249725484059963, 41117),\n",
       " (0.12548895093423626, 2898)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_10(movie,results):\n",
    "    ten = []\n",
    "    for sim, ind in results[:10]:\n",
    "        if movies['Title'][ind] != movie:\n",
    "            s = movies['Title'][ind]+' (score: '+str(sim)+')'\n",
    "            ten.append(s)\n",
    "    return ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frauds (score: 0.16056939582947824)',\n",
       " 'Duel in the Jungle (score: 0.15718873462135707)',\n",
       " 'The Fire Raisers (score: 0.15580892217745576)',\n",
       " 'Cover Up (score: 0.1485379138540403)',\n",
       " \"Killer's Carnival (score: 0.14042652859711635)\",\n",
       " 'Perdido por perdido (score: 0.13924014073325505)',\n",
       " 'The Gentleman from Nowhere (score: 0.1351215565899785)',\n",
       " 'Spring Fever (score: 0.1330696150046359)',\n",
       " 'Adulterous Wife: Dizzy (score: 0.13249725484059963)',\n",
       " 'Zombie Girl: The Movie (score: 0.12548895093423626)']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_10('Memento',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c67d541c1077>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmovies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m35155\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'movies' is not defined"
     ]
    }
   ],
   "source": [
    "movies['Title'][35155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id_to_index = {wikiid:i for i, wikiid in enumerate(movies['WikiID'])}\n",
    "#title_to_id = {t:i for t, i in zip(movies['Title'], movies['WikiID'])}\n",
    "#id_to_title = {v:k for k,v in title_to_id.items()}\n",
    "#title_to_index = {t:i for i, t in enumerate(movies['Title'])}\n",
    "#index_to_title = {v:k for k,v in title_to_index.items()}\n",
    "#movie_titles = [t for t in movies['Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_by_vocab = vectorizer.fit_transform([s for s in movies['Summary']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(movie, data):\n",
    "    wiki_id = title_to_id.get(movie)\n",
    "    ind = id_to_index.get(wiki_id)\n",
    "    summary = data['Summary'][ind]\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(user_mov, other_mov):\n",
    "    j = doc_by_vocab[title_to_index[other_mov]]\n",
    "    result = find_movie(user_mov)\n",
    "    if result[0] in movie_titles:\n",
    "        i = doc_by_vocab[title_to_index[result[0]]]\n",
    "    else:\n",
    "        i = vectorizer.transform([result[1]]).toarray()[0]\n",
    "    cosim = np.dot(i,j) / (np.linalg.norm(i)*np.linalg.norm(j))\n",
    "    return cosim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
